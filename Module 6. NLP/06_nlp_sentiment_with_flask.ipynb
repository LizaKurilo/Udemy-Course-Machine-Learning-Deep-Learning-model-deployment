{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06-nlp_sentiment_with_flask.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05NcT8B-1lCU"
      },
      "source": [
        "## Upload and unzip tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bep1I0N1MBm",
        "outputId": "0bf70feb-4e09-42e6-9230-a226fcc709ab"
      },
      "source": [
        "!unzip text_classifier_model_tf.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  text_classifier_model_tf.zip\n",
            "   creating: text_classifier_model/\n",
            "   creating: text_classifier_model/1/\n",
            "  inflating: text_classifier_model/1/saved_model.pb  \n",
            "   creating: text_classifier_model/1/assets/\n",
            "   creating: text_classifier_model/1/variables/\n",
            "  inflating: text_classifier_model/1/variables/variables.index  \n",
            "  inflating: text_classifier_model/1/variables/variables.data-00000-of-00001  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36piozEJ1i4F",
        "outputId": "86ca3ab3-a9c6-4393-e74a-bf5f0b511b9d"
      },
      "source": [
        "!wget https://github.com/futurexskill/ml-model-deployment/raw/main/tfidfmodel.pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-20 15:12:31--  https://github.com/futurexskill/ml-model-deployment/raw/main/tfidfmodel.pickle\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/tfidfmodel.pickle [following]\n",
            "--2021-04-20 15:12:31--  https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/tfidfmodel.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49660 (48K) [application/octet-stream]\n",
            "Saving to: ‘tfidfmodel.pickle’\n",
            "\n",
            "tfidfmodel.pickle   100%[===================>]  48.50K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-20 15:12:31 (4.07 MB/s) - ‘tfidfmodel.pickle’ saved [49660/49660]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysutn-7B1wvt",
        "outputId": "96d2b89a-6abc-4b70-cd56-486181801ae7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t       text_classifier_model_tf.zip\n",
            "text_classifier_model  tfidfmodel.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbsih3Rp5nwY"
      },
      "source": [
        "## Load tensorflow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YozpPqwj1zQD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVxKkm3D12WU"
      },
      "source": [
        "model = load_model('text_classifier_model/1/')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNQ3l_DV2Ana",
        "outputId": "d677aae1-bc0c-49ec-c73b-763d3f02ec28"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               234000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1002      \n",
            "=================================================================\n",
            "Total params: 485,502\n",
            "Trainable params: 485,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itZDp-FG5qxO"
      },
      "source": [
        "## Load tfidf model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJmQImdO2Ceg"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLzfyXnO2E2B"
      },
      "source": [
        "with open('tfidfmodel.pickle', 'rb') as file:\n",
        "  tfidf = pickle.load(file)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU6MKSba5uo0"
      },
      "source": [
        "## Flask server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I0u54Sr2NXo",
        "outputId": "4ae569ea-3a6e-40fb-fe63-26aab8f5c919"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjIjNNZ42Phg"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHmL02W02ePv"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY66BN6L2iWO"
      },
      "source": [
        "@app.route('/answer', methods=[\"POST\"], endpoint='answer')\n",
        "def text_classifier():\n",
        "    request_data = request.get_json(force=True)\n",
        "    text = request_data['sentence']\n",
        "    print(f'Sentence: {text}')\n",
        "    text_list = []\n",
        "    text_list.append(text)\n",
        "    print(text_list)\n",
        "    numeric_text = tfidf.transform(text_list).toarray()\n",
        "    output = model.predict(numeric_text)\n",
        "    print(f\"Prediction: {output}\")\n",
        "    sentiment = 'unknown'\n",
        "    if output[0][0] > 0.5:\n",
        "      print('Negative prediction')\n",
        "      sentiment = 'negative'\n",
        "    else:\n",
        "      print('Positive prediction')\n",
        "      sentiment = 'positive'\n",
        "    print(f\"Prediction: {sentiment}\")\n",
        "    return f\"The prediction is {sentiment}\""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8IeFCXJ3BPR",
        "outputId": "aa91b435-8644-4931-93b4-633f759d6a32"
      },
      "source": [
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://d5494751be4d.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2021 15:28:41] \"\u001b[37mPOST /answer HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentence: Bad perfomance by India\n",
            "['Bad perfomance by India']\n",
            "Prediction: [[1.0000000e+00 3.6861845e-08]]\n",
            "Negative prediction\n",
            "Prediction: negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2021 15:28:59] \"\u001b[37mPOST /answer HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentence: good perfomance by India\n",
            "['good perfomance by India']\n",
            "Prediction: [[0.2098132 0.7901868]]\n",
            "Positive prediction\n",
            "Prediction: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsU9F4rA3m9j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}